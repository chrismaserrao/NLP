{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e90Jy6ZEONKP"
      },
      "outputs": [],
      "source": [
        "#SIMILARITY MESURES FOR DISTANCE COMMONLY USED IN NLP:\n",
        "- 1. Longest Common Substring (LCS),\n",
        "Character based similarty - considers length of the longest string, returns lenght of that string which is a substring of both strings.\n",
        "- 2. Levenshtein Edit Distance,\n",
        " It quantifies how dissimilar two text units are to one another by\n",
        "  computing the minimum number of single-character edits\n",
        "  (replacement, deletion and insertion operations) required to convert text unit 1 into text unit 2.\n",
        "-3.  Hamming Distance,\n",
        "Hamming distance between two equal size strings measures the minimum number of replacements required to\n",
        "change one string into the other.\n",
        "- 4. Cosine Similarity,\n",
        " the measure of similarity between two non-zero vectors\n",
        " cosine of the angle between two vectors\n",
        "- 5. Jaccard Distance,\n",
        "- 6. Euclidean Distance,\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TyPY_Ay7dGPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample Documents\n",
        "doc1 = \"Machine learning is amazing. It is a subfield of artificial intelligence.\"\n",
        "doc2 = \"Artificial intelligence includes machine learning and deep learning.\"\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
        "    tokens = [word for word in tokens if word.isalnum()]  # Remove punctuation\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Preprocessing documents\n",
        "doc1_clean = preprocess(doc1)\n",
        "doc2_clean = preprocess(doc2)\n",
        "\n",
        "def cosine_similarity_method(doc1, doc2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([doc1, doc2])\n",
        "    return cosine_similarity(vectors[0], vectors[1])[0][0]\n",
        "\n",
        "def jaccard_similarity_method(doc1, doc2):\n",
        "    set1, set2 = set(doc1.split()), set(doc2.split())\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "# Compute Similarities\n",
        "cosine_sim = cosine_similarity_method(doc1_clean, doc2_clean)\n",
        "jaccard_sim = jaccard_similarity_method(doc1_clean, doc2_clean)\n",
        "\n",
        "# Print Results\n",
        "print(f\"Cosine Similarity: {cosine_sim:.4f}\")\n",
        "print(f\"Jaccard Similarity: {jaccard_sim:.4f}\")\n"
      ],
      "metadata": {
        "id": "cOIY0mMvAGYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e82631-4191-4396-b9fe-0cf4e56a5876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.5359\n",
            "Jaccard Similarity: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"small_text\", \"large_text\"]\n",
        "count_vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "count_vectorizer = CountVectorizer()\n",
        "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "\n",
        "doc_term_matrix = sparse_matrix.todense()\n",
        "df = pd.DataFrame(\n",
        "   doc_term_matrix,\n",
        "   columns=count_vectorizer.get_feature_names_out(),\n",
        "   index=[\"small_text\", \"large_text\"],\n",
        ")\n",
        "print(df)\n",
        "print(cosine_similarity(df, df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q92ayA7z_NsH",
        "outputId": "1d969dfb-3a7a-40c7-e175-7bf8715cfe7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            large_text  small_text\n",
            "small_text           0           1\n",
            "large_text           1           0\n",
            "[[1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Sentiment Analysis Using Pretrained NLP Libraries (TextBlob, VADER, or Flair)\n",
        "\n",
        "Implement sentiment analysis using a pretrained NLP library and analyze sentiment features such as\n",
        "polarity and subjectivity.\n",
        "\n",
        "Task:\n",
        "• Use TextBlob for analysing the text (Any other library also you can use)\n",
        "• Preprocess the text dataset and apply the chosen library for sentiment extraction.\n",
        "\n",
        "• Analyze two key features:\n",
        "o Polarity: Determines whether the sentiment is positive, negative, or neutral (range: -\n",
        "1 to +1).\n",
        "o Subjectivity: Measures the degree of opinion or factual information (range: 0 to 1)."
      ],
      "metadata": {
        "id": "otJfexXEi4AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment analysis\n",
        "doc1 = '''I love sunny days! They make me feel so happy. '''\n",
        "\n",
        "doc2 = \"\"\"\n",
        "The weather today is absolutely beautiful. The sun is shining brightly, casting a warm and golden glow over everything it touches.\n",
        "The sky is a brilliant shade of blue, with barely a cloud in sight. Birds are singing their cheerful songs, flitting from tree to tree as if they,\n",
        "too, are enjoying the wonderful weather. A gentle breeze rustles the leaves, creating a soothing, rhythmic sound that adds to the peaceful atmosphere.\n",
        " It feels like one of those perfect days—where nature seems to be in harmony, offering a moment of serenity amidst the usual chaos of life.\n",
        "\n",
        "Despite this picturesque setting, I can’t help but feel a bit anxious about the upcoming week.\n",
        " There’s so much to do, so many responsibilities to juggle, and I find myself worrying about whether\n",
        "  I’ll have enough time to complete everything on my to-do list. Work deadlines are approaching, personal commitments are piling up,\n",
        "  and there’s a lingering sense of pressure that I just can’t shake. No matter how much I plan, it always seems like time moves faster than I expect.\n",
        "  The thought of falling behind or not meeting expectations gnaws at the back of my mind, making it difficult to fully relax.\n",
        "\n",
        "But even as these worries creep in, I remind myself that dwelling on stress won’t help me move forward.\n",
        " I take a deep breath and try to shift my perspective. Instead of focusing on the weight of upcoming tasks,\n",
        " I choose to appreciate the beauty of the present moment. The sun is warm on my skin, the fresh air fills my lungs,\n",
        "  and the melody of chirping birds is a gentle reminder that life isn’t just about work and deadlines—it’s also about moments like these, where I can pause and just be.\n",
        "\n",
        "I know that if I approach the week with a positive mindset and a little bit of planning,\n",
        "I can manage my time effectively. It’s all about balance—finding time to be productive while also making room for relaxation and joy.\n",
        " I make a mental note to break my tasks into manageable steps, to prioritize what truly needs to be done, and to remind myself that perfection isn’t necessary—progress is.\n",
        "\n",
        "I also remind myself to be kind to myself.\n",
        "It’s easy to get caught up in expectations and self-imposed pressure, but at the end of the day, I’m only human.\n",
        " There will always be things to do, but there will also always be sunny days like this, waiting to be enjoyed.\n",
        " Instead of letting stress consume me, I can embrace the idea that life is a mix of challenges and simple pleasures.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "BNXtbDomiuiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    return {\n",
        "        'polarity': blob.sentiment.polarity,\n",
        "        'subjectivity': blob.sentiment.subjectivity\n",
        "    }\n",
        "\n",
        "\n",
        "small_text_sentiment = analyze_sentiment(small_text)\n",
        "print(\"Small Text Sentiment Analysis:\")\n",
        "print(f\"Polarity: {small_text_sentiment['polarity']}, Subjectivity: {small_text_sentiment['subjectivity']}\")\n",
        "\n",
        "\n",
        "large_text_sentiment = analyze_sentiment(large_text)\n",
        "print(\"\\nLarge Text Sentiment Analysis:\")\n",
        "print(f\"Polarity: {large_text_sentiment['polarity']}, Subjectivity: {large_text_sentiment['subjectivity']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpR8Ud--lSTW",
        "outputId": "36ce1440-1881-4825-97be-62d7e1f80b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small Text Sentiment Analysis:\n",
            "Polarity: 0.7125, Subjectivity: 0.8\n",
            "\n",
            "Large Text Sentiment Analysis:\n",
            "Polarity: 0.2566611234294161, Subjectivity: 0.5533153838031886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same text but preprocessed\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "filtered_text =\n"
      ],
      "metadata": {
        "id": "IA0I-v0vms7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using basian classifier"
      ],
      "metadata": {
        "id": "GbEK_sH2aL4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"I love this movie! It's fantastic!\",\n",
        "        \"This film is terrible. I hate it.\",\n",
        "        \"Amazing storyline and great acting!\",\n",
        "        \"Worst movie ever. So boring and dull.\",\n",
        "        \"The plot was good but the acting was bad.\",\n",
        "        \"Absolutely loved it! Must watch!\",\n",
        "        \"Horrible movie. Waste of time.\",\n",
        "        \"It's okay, not the best but not the worst either.\"\n",
        "    ],\n",
        "    \"sentiment\": [1, 0, 1, 0, 1, 1, 0, 1]  # 1: Positive, 0: Negative\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum()]  # Remove punctuation\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "# Feature extraction (TF-IDF)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
        "y = df[\"sentiment\"]\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Naïve Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ixbUpHndHR7",
        "outputId": "ada6f235-7d5a-4d91-9cdb-fdea18517f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###sentiment classification using RNN\n"
      ],
      "metadata": {
        "id": "1gZulC3jig2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/twitter_training.csv')"
      ],
      "metadata": {
        "id": "qUkkZqtsinnc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-cIyx4cbiz8O",
        "outputId": "452bb4c9-c569-4a34-b15b-504cc3bc4ebc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   2401  Borderlands  Positive  \\\n",
              "0  2401  Borderlands  Positive   \n",
              "1  2401  Borderlands  Positive   \n",
              "2  2401  Borderlands  Positive   \n",
              "3  2401  Borderlands  Positive   \n",
              "4  2401  Borderlands  Positive   \n",
              "\n",
              "  im getting on borderlands and i will murder you all ,  \n",
              "0  I am coming to the borders and I will kill you...     \n",
              "1  im getting on borderlands and i will kill you ...     \n",
              "2  im coming on borderlands and i will murder you...     \n",
              "3  im getting on borderlands 2 and i will murder ...     \n",
              "4  im getting into borderlands and i can murder y...     "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5d06d89-58e0-4923-b4f3-7e140a02c107\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2401</th>\n",
              "      <th>Borderlands</th>\n",
              "      <th>Positive</th>\n",
              "      <th>im getting on borderlands and i will murder you all ,</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5d06d89-58e0-4923-b4f3-7e140a02c107')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5d06d89-58e0-4923-b4f3-7e140a02c107 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5d06d89-58e0-4923-b4f3-7e140a02c107');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e748edd6-8611-4fe3-bf5e-485af8e1fb8e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e748edd6-8611-4fe3-bf5e-485af8e1fb8e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e748edd6-8611-4fe3-bf5e-485af8e1fb8e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 74681,\n  \"fields\": [\n    {\n      \"column\": \"2401\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3740,\n        \"min\": 1,\n        \"max\": 13200,\n        \"num_unique_values\": 12447,\n        \"samples\": [\n          1616,\n          2660,\n          2335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Borderlands\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Cyberpunk2077\",\n          \"Microsoft\",\n          \"TomClancysRainbowSix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Positive\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Neutral\",\n          \"Irrelevant\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"im getting on borderlands and i will murder you all ,\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 69490,\n        \"samples\": [\n          \"so how does my stained glass open facebook account girl already have 200 likes!!!! and i sure am so!!??? oh thankful!??!?!\",\n          \"How not to get bored about every damn thing in life.\",\n          \"The Best Perfect Way to Protect All the Planet Samsung Galaxy Note10 + By buff. ly / The 2zkjIhU..\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset without headers\n",
        "df = pd.read_csv('/content/twitter_training.csv', header=None, names=['id', 'unused', 'sentiment', 'text'])\n",
        "\n",
        "# Check dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Convert labels to binary (Positive -> 1, Negative -> 0)\n",
        "df['Label'] = df['sentiment'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
        "\n",
        "# Text Cleaning Function\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
        "    return text\n",
        "\n",
        "df['Cleaned_Text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['Cleaned_Text'])\n",
        "\n",
        "# Convert to Sequences\n",
        "sequences = tokenizer.texts_to_sequences(df['Cleaned_Text'])\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "y = np.array(df['Label'])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# RNN Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=64, input_length=max_length),\n",
        "    SimpleRNN(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate RNN\n",
        "y_pred_rnn = (model.predict(X_test) > 0.5).astype('int')\n",
        "print(\"RNN Accuracy:\", accuracy_score(y_test, y_pred_rnn))\n",
        "print(classification_report(y_test, y_pred_rnn))\n",
        "\n",
        "# Naïve Bayes for Comparison\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(df['Cleaned_Text'])\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train_tfidf)\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test_tfidf, y_pred_nb))\n",
        "print(classification_report(y_test_tfidf, y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQBn9eNfkFeN",
        "outputId": "575aa538-4724-4d7c-b9dd-d5226897f28f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id       unused sentiment  \\\n",
            "0  2401  Borderlands  Positive   \n",
            "1  2401  Borderlands  Positive   \n",
            "2  2401  Borderlands  Positive   \n",
            "3  2401  Borderlands  Positive   \n",
            "4  2401  Borderlands  Positive   \n",
            "\n",
            "                                                text  \n",
            "0  im getting on borderlands and i will murder yo...  \n",
            "1  I am coming to the borders and I will kill you...  \n",
            "2  im getting on borderlands and i will kill you ...  \n",
            "3  im coming on borderlands and i will murder you...  \n",
            "4  im getting on borderlands 2 and i will murder ...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 52ms/step - accuracy: 0.7234 - loss: 0.5944 - val_accuracy: 0.7168 - val_loss: 0.5964\n",
            "Epoch 2/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 47ms/step - accuracy: 0.7242 - loss: 0.5895 - val_accuracy: 0.7168 - val_loss: 0.5978\n",
            "Epoch 3/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 42ms/step - accuracy: 0.7231 - loss: 0.5906 - val_accuracy: 0.7168 - val_loss: 0.5959\n",
            "Epoch 4/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 43ms/step - accuracy: 0.7210 - loss: 0.5925 - val_accuracy: 0.7168 - val_loss: 0.5965\n",
            "Epoch 5/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 42ms/step - accuracy: 0.7207 - loss: 0.5930 - val_accuracy: 0.7168 - val_loss: 0.5959\n",
            "Epoch 6/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 43ms/step - accuracy: 0.7262 - loss: 0.5874 - val_accuracy: 0.7168 - val_loss: 0.5960\n",
            "Epoch 7/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 44ms/step - accuracy: 0.7193 - loss: 0.5941 - val_accuracy: 0.7168 - val_loss: 0.5963\n",
            "Epoch 8/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 45ms/step - accuracy: 0.7204 - loss: 0.5930 - val_accuracy: 0.7168 - val_loss: 0.5959\n",
            "Epoch 9/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 44ms/step - accuracy: 0.7220 - loss: 0.5914 - val_accuracy: 0.7168 - val_loss: 0.5959\n",
            "Epoch 10/10\n",
            "\u001b[1m1868/1868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 44ms/step - accuracy: 0.7229 - loss: 0.5906 - val_accuracy: 0.7168 - val_loss: 0.5959\n",
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
            "RNN Accuracy: 0.7168106045390641\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.84     10707\n",
            "           1       0.00      0.00      0.00      4230\n",
            "\n",
            "    accuracy                           0.72     14937\n",
            "   macro avg       0.36      0.50      0.42     14937\n",
            "weighted avg       0.51      0.72      0.60     14937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Bayes Accuracy: 0.8016335274820915\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.99      0.88     10707\n",
            "           1       0.95      0.32      0.48      4230\n",
            "\n",
            "    accuracy                           0.80     14937\n",
            "   macro avg       0.87      0.66      0.68     14937\n",
            "weighted avg       0.83      0.80      0.76     14937\n",
            "\n"
          ]
        }
      ]
    }
  ]
}